{
    "additionDate": "2021-03-19T09:15:39Z",
    "bioagentsCURIE": "bioagents:art-net",
    "bioagentsID": "art-net",
    "confidence_flag": "agent",
    "description": "ART-Net (Augmented Reality Agent Network) is a integrated lightweight framework for agent detection, segmentation, and 3D pose estimation from a laparoscopic image.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Image analysis",
                    "uri": "http://edamontology.org/operation_3443"
                },
                {
                    "term": "Image annotation",
                    "uri": "http://edamontology.org/operation_3553"
                },
                {
                    "term": "Visualisation",
                    "uri": "http://edamontology.org/operation_0337"
                }
            ]
        }
    ],
    "homepage": "https://github.com/kamruleee51/ART-Net",
    "lastUpdate": "2021-04-11T09:46:39Z",
    "name": "ART-Net",
    "owner": "Kigaard",
    "publication": [
        {
            "doi": "10.1016/J.MEDIA.2021.101994",
            "metadata": {
                "abstract": "© 2021 Elsevier B.V.Background and objective:Surgical agent detection, segmentation, and 3D pose estimation are crucial components in Computer-Assisted Laparoscopy (CAL). The existing frameworks have two main limitations. First, they do not integrate all three components. Integration is critical; for instance, one should not attempt computing pose if detection is negative. Second, they have highly specific requirements, such as the availability of a CAD model. We propose an integrated and generic framework whose sole requirement for the 3D pose is that the agent shaft is cylindrical. Our framework makes the most of deep learning and geometric 3D vision by combining a proposed Convolutional Neural Network (CNN) with algebraic geometry. We show two applications of our framework in CAL: agent-aware rendering in Augmented Reality (AR) and agent-based 3D measurement. Methods:We name our CNN as ART-Net (Augmented Reality Agent Network). It has a Single Input Multiple Output (SIMO) architecture with one encoder and multiple decoders to achieve detection, segmentation, and geometric primitive extraction. These primitives are the agent edge-lines, mid-line, and tip. They allow the agent's 3D pose to be estimated by a fast algebraic procedure. The framework only proceeds if a agent is detected. The accuracy of segmentation and geometric primitive extraction is boosted by a new Full resolution feature map Generator (FrG). We extensively evaluate the proposed framework with the EndoVis and new proposed datasets. We compare the segmentation results against several variants of the Fully Convolutional Network (FCN) and U-Net. Several ablation studies are provided for detection, segmentation, and geometric primitive extraction. The proposed datasets are surgery videos of different patients. Results:In detection, ART-Net achieves 100.0% in both average precision and accuracy. In segmentation, it achieves 81.0% in mean Intersection over Union (mIoU) on the robotic EndoVis dataset (articulated agent), where it outperforms both FCN and U-Net, by 4.5pp and 2.9pp, respectively. It achieves 88.2% in mIoU on the remaining datasets (non-articulated agent). In geometric primitive extraction, ART-Net achieves 2.45∘ and 2.23∘ in mean Arc Length (mAL) error for the edge-lines and mid-line, respectively, and 9.3 pixels in mean Euclidean distance error for the agent-tip. Finally, in terms of 3D pose evaluated on animal data, our framework achieves 1.87 mm, 0.70 mm, and 4.80 mm mean absolute errors on the X, Y, and Z coordinates, respectively, and 5.94∘ angular error on the shaft orientation. It achieves 2.59 mm and 1.99 mm in mean and median location error of the agent head evaluated on patient data. Conclusions:The proposed framework outperforms existing ones in detection and segmentation. Compared to separate networks, integrating the tasks in a single network preserves accuracy in detection and segmentation but substantially improves accuracy in geometric primitive extraction. Overall, our framework has similar or better accuracy in 3D pose estimation while largely improving robustness against the very challenging imaging conditions of laparoscopy. The source code of our framework and our annotated dataset will be made publicly available at https://github.com/kamruleee51/ART-Net.",
                "authors": [
                    {
                        "name": "Bartoli A."
                    },
                    {
                        "name": "Calvet L."
                    },
                    {
                        "name": "Hasan M.K."
                    },
                    {
                        "name": "Rabbani N."
                    }
                ],
                "citationCount": 3,
                "date": "2021-05-01T00:00:00Z",
                "journal": "Medical Image Analysis",
                "title": "Detection, segmentation, and 3D pose estimation of surgical agents using convolutional neural networks and algebraic geometry"
            },
            "pmid": "33611053"
        }
    ],
    "agentType": [
        "Workbench"
    ],
    "topic": [
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        },
        {
            "term": "Surgery",
            "uri": "http://edamontology.org/topic_3421"
        }
    ]
}
