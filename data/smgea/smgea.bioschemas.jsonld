{
  "@context": {
    "bioagents": "https://bio.agents/ontology/",
    "bsc": "http://bioschemas.org/",
    "bsct": "http://bioschemas.org/types/",
    "dct": "http://purl.org/dc/terms/",
    "edam": "http://edamontology.org/",
    "owl": "http://www.w3.org/2002/07/owl#",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@graph": [
    {
      "@id": "https://bio.agents/smgea",
      "@type": "sc:SoftwareApplication",
      "dct:conformsTo": "https://bioschemas.org/profiles/ComputationalAgent/0.6-DRAFT",
      "sc:applicationSubCategory": [
        {
          "@id": "edam:topic_3474"
        },
        {
          "@id": "edam:topic_0749"
        }
      ],
      "sc:citation": [
        {
          "@id": "https://doi.org/10.1109/TNNLS.2020.3039295"
        },
        "pubmed:33296311"
      ],
      "sc:description": "A New Ensemble Adversarial Attack Powered by Long-Term Gradient Memories.\n\nDeep neural networks are vulnerable to adversarial attacks. More importantly, some adversarial examples crafted against an ensemble of source models transfer to other target models and, thus, pose a security threat to black-box applications (when attackers have no access to the target models). Current transfer-based ensemble attacks, however, only consider a limited number of source models to craft an adversarial example and, thus, obtain poor transferability. Besides, recent query-based black-box attacks, which require numerous queries to the target model, not only come under suspicion by the target model but also cause expensive query cost. In this article, we propose a novel transfer-based black-box attack, dubbed serial-minigroup-ensemble-attack (SMGEA)",
      "sc:name": "SMGEA",
      "sc:url": "https://github.com/CZHQuality/AAA-Pix2pix"
    },
    {
      "@id": "https://doi.org/10.1109/TNNLS.2020.3039295",
      "@type": "sc:CreativeWork"
    }
  ]
}