{
    "additionDate": "2020-09-23T06:05:05Z",
    "bioagentsCURIE": "bioagents:fracridge",
    "bioagentsID": "fracridge",
    "credit": [
        {
            "email": "arokem@uw.edu",
            "name": "Ariel Rokem",
            "orcidid": "https://orcid.org/0000-0003-0679-1985",
            "typeEntity": "Person"
        },
        {
            "email": "kay@umn.edu",
            "name": "Kendrick Kay",
            "orcidid": "https://orcid.org/0000-0001-6604-9155",
            "typeEntity": "Person"
        }
    ],
    "description": "Ridge regression (RR) is a regularization technique that penalizes the L2-norm of the coefficients in linear regression. One of the challenges of using RR is the need to set a hyperparameter (α) that controls the amount of regularization. Cross-validation is typically used to select the best α from a set of candidates. However, efficient and appropriate selection of α can be challenging, particularly where large amounts of data are analyzed. Because the selected α depends on the scale of the data and predictors, it is also not straightforwardly interpretable.\n\nIn fracridge, we reparameterize RR in terms of the ratio γ between the L2-norms of the regularized and unregularized coefficients. This approach, called fractional RR (FRR), has several benefits: the solutions obtained for different γ are guaranteed to vary, guarding against wasted calculations, and automatically span the relevant range of regularization, avoiding the need for arduous manual exploration.",
    "download": [
        {
            "type": "Software package",
            "url": "https://github.com/nrdg/fracridge/releases/tag/1.2"
        }
    ],
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Regression analysis",
                    "uri": "http://edamontology.org/operation_3659"
                },
                {
                    "term": "Standardisation and normalisation",
                    "uri": "http://edamontology.org/operation_3435"
                }
            ]
        }
    ],
    "homepage": "https://nrdg.github.io/fracridge/",
    "language": [
        "MATLAB",
        "Python"
    ],
    "lastUpdate": "2021-03-11T11:01:49Z",
    "license": "BSD-2-Clause",
    "link": [
        {
            "type": [
                "Other"
            ],
            "url": "https://nrdg.github.io/fracridge"
        }
    ],
    "name": "fracridge",
    "owner": "arokem",
    "publication": [
        {
            "doi": "10.1093/GIGASCIENCE/GIAA133",
            "metadata": {
                "abstract": "© 2020 The Author(s).Background: Ridge regression is a regularization technique that penalizes the L2-norm of the coefficients in linear regression. One of the challenges of using ridge regression is the need to set a hyperparameter (α) that controls the amount of regularization. Cross-validation is typically used to select the best α from a set of candidates. However, efficient and appropriate selection of α can be challenging. This becomes prohibitive when large amounts of data are analyzed. Because the selected α depends on the scale of the data and correlations across predictors, it is also not straightforwardly interpretable. Results: The present work addresses these challenges through a novel approach to ridge regression. We propose to reparameterize ridge regression in terms of the ratio γ between the L2-norms of the regularized and unregularized coefficients. We provide an algorithm that efficiently implements this approach, called fractional ridge regression, as well as open-source software implementations in Python and MATLAB (https://github.com/nrdg/fracridge). We show that the proposed method is fast and scalable for large-scale data problems. In brain imaging data, we demonstrate that this approach delivers results that are straightforward to interpret and compare across models and datasets. Conclusion: Fractional ridge regression has several benefits: the solutions obtained for different γ are guaranteed to vary, guarding against wasted calculations; and automatically span the relevant range of regularization, avoiding the need for arduous manual exploration. These properties make fractional ridge regression particularly suitable for analysis of large complex datasets.",
                "authors": [
                    {
                        "name": "Kay K."
                    },
                    {
                        "name": "Rokem A."
                    }
                ],
                "date": "2021-12-01T00:00:00Z",
                "journal": "GigaScience",
                "title": "Fractional ridge regression: A fast, interpretable reparameterization of ridge regression"
            },
            "pmcid": "PMC7702219",
            "pmid": "33252656"
        }
    ],
    "topic": [
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        }
    ],
    "validated": 1,
    "version": [
        "1.2.1"
    ]
}
