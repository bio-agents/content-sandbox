{
    "accessibility": "Open access",
    "additionDate": "2022-10-06T09:24:45.174744Z",
    "bioagentsCURIE": "bioagents:bitr-unet",
    "bioagentsID": "bitr-unet",
    "confidence_flag": "agent",
    "cost": "Free of charge",
    "credit": [
        {
            "name": "Qiran Jia"
        },
        {
            "name": "Hai Shu",
            "typeEntity": "Person"
        }
    ],
    "description": "A CNN-Transformer combined model, called BiTr-Unet, with specific modifications for brain tumor segmentation on multi-modal MRI scans",
    "editPermission": {
        "type": "public"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Data retrieval",
                    "uri": "http://edamontology.org/operation_2422"
                },
                {
                    "term": "Standardisation and normalisation",
                    "uri": "http://edamontology.org/operation_3435"
                },
                {
                    "term": "Validation",
                    "uri": "http://edamontology.org/operation_2428"
                }
            ]
        }
    ],
    "homepage": "https://github.com/JustaTinyDot/BiTr-Unet",
    "language": [
        "Python"
    ],
    "lastUpdate": "2022-11-06T13:25:27.226496Z",
    "license": "Apache-2.0",
    "name": "BiTr-Unet",
    "owner": "Chan019",
    "publication": [
        {
            "doi": "10.1007/978-3-031-09002-8_1",
            "metadata": {
                "abstract": "Â© 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.Convolutional neural networks (CNNs) have achieved remarkable success in automatically segmenting organs or lesions on 3D medical images. Recently, vision transformer networks have exhibited exceptional performance in 2D image classification tasks. Compared with CNNs, transformer networks have an appealing advantage of extracting long-range features due to their self-attention algorithm. Therefore, we propose a CNN-Transformer combined model, called BiTr-Unet, with specific modifications for brain tumor segmentation on multi-modal MRI scans. Our BiTr-Unet achieves good performance on the BraTS2021 validation dataset with median Dice score 0.9335, 0.9304 and 0.8899, and median Hausdorff distance 2.8284, 2.2361 and 1.4142 for the whole tumor, tumor core, and enhancing tumor, respectively. On the BraTS2021 testing dataset, the corresponding results are 0.9257, 0.9350 and 0.8874 for Dice score, and 3, 2.2361 and 1.4142 for Hausdorff distance. The code is publicly available at https://github.com/JustaTinyDot/BiTr-Unet.",
                "authors": [
                    {
                        "name": "Jia Q."
                    },
                    {
                        "name": "Shu H."
                    }
                ],
                "date": "2022-01-01T00:00:00Z",
                "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
                "title": "BiTr-Unet: A CNN-Transformer Combined Network for MRI Brain Tumor Segmentation"
            },
            "pmcid": "PMC9396958",
            "pmid": "36005929"
        }
    ],
    "agentType": [
        "Command-line agent"
    ],
    "topic": [
        {
            "term": "MRI",
            "uri": "http://edamontology.org/topic_3444"
        },
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "Medical imaging",
            "uri": "http://edamontology.org/topic_3384"
        }
    ]
}
