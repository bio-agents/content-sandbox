{
    "additionDate": "2020-01-14T20:10:23Z",
    "bioagentsCURIE": "bioagents:scanpath",
    "bioagentsID": "scanpath",
    "confidence_flag": "agent",
    "description": "Visual Scanpath Prediction using IOR-ROI Recurrent Mixture Density Network.",
    "editPermission": {
        "type": "public"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Pathway or network prediction",
                    "uri": "http://edamontology.org/operation_3439"
                },
                {
                    "term": "Pathway or network visualisation",
                    "uri": "http://edamontology.org/operation_3083"
                },
                {
                    "term": "Regression analysis",
                    "uri": "http://edamontology.org/operation_3659"
                }
            ]
        }
    ],
    "homepage": "https://github.com/sunwj/scanpath",
    "lastUpdate": "2021-01-16T12:54:48Z",
    "license": "LGPL-3.0",
    "name": "scanpath",
    "owner": "Pub2Agents",
    "publication": [
        {
            "doi": "10.1109/TPAMI.2019.2956930",
            "metadata": {
                "abstract": "Â© 1979-2012 IEEE.A visual scanpath represents the human eye movements when scanning the visual field for acquiring and receiving visual information. Predicting visual scanpaths when a certain stimulus is presented plays an important role in modeling overt human visual attention and search behavior. In this paper, we presented an 'Inhibition of Return - Region of Interest' (IOR-ROI) recurrent mixture density network based framework learning to produce human-like visual scanpaths under task-free viewing conditions. The proposed model simultaneously predicts a sequence of ordered fixation positions and their corresponding fixation durations. Our model integrates bottom-up features and semantic features extracted by convolutional neural networks. Then the integrated feature maps are fed into the IOR-ROI Long Short-Term Memory (LSTM) which is the core component of the proposed model. The IOR-ROI LSTM is a dual LSTM unit, i.e., the IOR-LSTM and the ROI-LSTM, capturing IOR dynamics and gaze shift behavior simultaneously. IOR-LSTM simulates the visual working memory to adaptively maintain and update visual information regarding previously fixated regions. ROI-LSTM is responsible for predicting the next possible ROIs given the spatially inhibited image feature maps on the feature-wise basis. Fixation duration is predicted by a regression neural network given the viewing history and image feature maps corresponding to currently fixated ROI. Considering the eye movement pattern variations among subjects, a mixture density network is adopted to model the next fixation distribution as Gaussian mixtures and the fixation duration is also modeled using Gaussian distribution. Our model is evaluated on the OSIE and MIT low resolution eye-tracking datasets and experimental results indicate that the proposed method can achieve superior performance in predicting visual scanpaths. The code will be publicly available on URL: https://github.com/sunwj/scanpath.",
                "authors": [
                    {
                        "name": "Chen Z."
                    },
                    {
                        "name": "Sun W."
                    },
                    {
                        "name": "Wu F."
                    }
                ],
                "date": "2021-06-01T00:00:00Z",
                "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "title": "Visual Scanpath Prediction Using IOR-ROI Recurrent Mixture Density Network"
            },
            "pmid": "31796389"
        }
    ],
    "topic": [
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        },
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "Mapping",
            "uri": "http://edamontology.org/topic_0102"
        }
    ],
    "validated": 1
}
