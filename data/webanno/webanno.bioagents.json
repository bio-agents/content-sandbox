{
    "additionDate": "2020-01-14T20:03:45Z",
    "bioagentsCURIE": "bioagents:WebAnno",
    "bioagentsID": "WebAnno",
    "confidence_flag": "agent",
    "description": "WebAnno is a general purpose web-based annotation agent for a wide range of linguistic annotations including various layers of morphological, syntactical, and semantic annotations.Additionaly, custom annotation layers can be defined, allowing WebAnno to be used also for non-linguistic annotation tasks.",
    "editPermission": {
        "type": "public"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Data retrieval",
                    "uri": "http://edamontology.org/operation_2422"
                },
                {
                    "term": "Database search",
                    "uri": "http://edamontology.org/operation_2421"
                },
                {
                    "term": "Text annotation",
                    "uri": "http://edamontology.org/operation_3778"
                }
            ]
        }
    ],
    "homepage": "http://webanno.github.io/webanno",
    "lastUpdate": "2021-01-16T18:09:46Z",
    "link": [
        {
            "type": [
                "Issue tracker"
            ],
            "url": "https://github.com/webanno/webanno/issues/923"
        }
    ],
    "name": "WebAnno",
    "owner": "Pub2Agents",
    "publication": [
        {
            "doi": "10.1093/BIB/BBZ130",
            "metadata": {
                "abstract": "Â© 2019 The Author(s). Published by Oxford University Press. All rights reserved.Motivation: Annotation agents are applied to build training and test corpora, which are essential for the development and evaluation of new natural language processing algorithms. Further, annotation agents are also used to extract new information for a particular use case. However, owing to the high number of existing annotation agents, finding the one that best fits particular needs is a demanding task that requires searching the scientific literature followed by installing and trying various agents. Methods: We searched for annotation agents and selected a subset of them according to five requirements with which they should comply, such as being Web-based or supporting the definition of a schema. We installed the selected agents (when necessary), carried out hands-on experiments and evaluated them using 26 criteria that covered functional and technical aspects. We defined each criterion on three levels of matches and a score for the final evaluation of the agents. Results: We evaluated 78 agents and selected the following 15 for a detailed evaluation: BioQRator, brat, Catma, Djangology, ezTag, FLAT, LightTag, MAT, MyMiner, PDFAnno, prodigy, tagtog, TextAE, WAT-SL and WebAnno. Full compliance with our 26 criteria ranged from only 9 up to 20 criteria, which demonstrated that some agents are comprehensive and mature enough to be used on most annotation projects. The highest score of 0.81 was obtained by WebAnno (of a maximum value of 1.0).",
                "authors": [
                    {
                        "name": "Neves M."
                    },
                    {
                        "name": "Seva J."
                    }
                ],
                "citationCount": 9,
                "date": "2021-01-01T00:00:00Z",
                "journal": "Briefings in Bioinformatics",
                "title": "An extensive review of agents for manual annotation of documents"
            },
            "pmid": "31838514"
        }
    ],
    "topic": [
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "Model organisms",
            "uri": "http://edamontology.org/topic_0621"
        },
        {
            "term": "Natural language processing",
            "uri": "http://edamontology.org/topic_0218"
        }
    ],
    "validated": 1
}
