{
    "accessibility": "Open access",
    "additionDate": "2022-01-10T13:54:09.817287Z",
    "bioagentsCURIE": "bioagents:prottrans",
    "bioagentsID": "prottrans",
    "confidence_flag": "agent",
    "cost": "Free of charge",
    "credit": [
        {
            "email": "ahmed.elnaggar@tum.de",
            "name": "Ahmed Elnaggar",
            "typeEntity": "Person",
            "typeRole": [
                "Primary contact"
            ]
        },
        {
            "email": "christian@dallago.us",
            "name": "Christian Dallago",
            "typeEntity": "Person",
            "typeRole": [
                "Primary contact"
            ]
        },
        {
            "email": "mheinzinger@rostlab.org",
            "name": "Michael Heinzinger",
            "typeEntity": "Person",
            "typeRole": [
                "Primary contact"
            ]
        },
        {
            "email": "wang_yu@hotmail.com",
            "name": "Yu Wang",
            "typeEntity": "Person",
            "typeRole": [
                "Primary contact"
            ]
        }
    ],
    "description": "ProtTrans is providing state of the art pre-trained models for proteins. ProtTrans was trained on thousands of GPUs from Summit and hundreds of Google TPUs using various Transformers Models.",
    "download": [
        {
            "type": "Source code",
            "url": "https://github.com/agemagician/ProtTrans/releases/tag/1.0"
        }
    ],
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Dimensionality reduction",
                    "uri": "http://edamontology.org/operation_3935"
                },
                {
                    "term": "Protein secondary structure prediction",
                    "uri": "http://edamontology.org/operation_0267"
                },
                {
                    "term": "Subcellular localisation prediction",
                    "uri": "http://edamontology.org/operation_2489"
                }
            ]
        }
    ],
    "homepage": "https://github.com/agemagician/ProtTrans",
    "language": [
        "Python"
    ],
    "lastUpdate": "2022-01-10T13:54:09.821504Z",
    "license": "AFL-3.0",
    "link": [
        {
            "type": [
                "Issue tracker"
            ],
            "url": "https://github.com/agemagician/ProtTrans/issues"
        }
    ],
    "name": "ProtTrans",
    "operatingSystem": [
        "Linux",
        "Mac",
        "Windows"
    ],
    "owner": "Kigaard",
    "publication": [
        {
            "doi": "10.1109/TPAMI.2021.3095381",
            "metadata": {
                "abstract": "CCBYComputational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models taken from NLP. These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The LMs were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw protein LM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks. The first was a per-residue prediction of protein secondary structure (3-state accuracy Q3=81%-87%); the second were per-protein predictions of protein sub-cellular localization (ten-state accuracy: Q10=81%) and membrane vs. water soluble (2-state accuracy Q2=91%). For the per-residue predictions the transfer of the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without using evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that protein LMs learned some of the grammar of the language of life. To facilitate future work, we released our models at https://github.com/agemagician/ProtTrans.",
                "authors": [
                    {
                        "name": "Angerer C."
                    },
                    {
                        "name": "Bhowmik D."
                    },
                    {
                        "name": "Dallago C."
                    },
                    {
                        "name": "Elnaggar A."
                    },
                    {
                        "name": "Feher T."
                    },
                    {
                        "name": "Gibbs T."
                    },
                    {
                        "name": "Heinzinger M."
                    },
                    {
                        "name": "Jones L."
                    },
                    {
                        "name": "Rehawi G."
                    },
                    {
                        "name": "Rost B."
                    },
                    {
                        "name": "Steinegger M."
                    },
                    {
                        "name": "Yu W."
                    }
                ],
                "citationCount": 8,
                "date": "2021-01-01T00:00:00Z",
                "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "title": "ProtTrans: Towards Cracking the Language of Lifes Code Through Self-Supervised Deep Learning and High Performance Computing"
            },
            "pmid": "34232869",
            "type": [
                "Primary"
            ]
        }
    ],
    "agentType": [
        "Script"
    ],
    "topic": [
        {
            "term": "Biophysics",
            "uri": "http://edamontology.org/topic_3306"
        },
        {
            "term": "Cell biology",
            "uri": "http://edamontology.org/topic_2229"
        },
        {
            "term": "Natural language processing",
            "uri": "http://edamontology.org/topic_0218"
        },
        {
            "term": "Protein secondary structure",
            "uri": "http://edamontology.org/topic_3542"
        }
    ]
}
