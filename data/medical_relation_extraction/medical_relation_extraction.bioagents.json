{
    "additionDate": "2020-01-14T20:15:54Z",
    "bioagentsCURIE": "bioagents:medical_relation_extraction",
    "bioagentsID": "medical_relation_extraction",
    "confidence_flag": "agent",
    "credit": [
        {
            "email": "mfwu@sina.com",
            "name": "Mingfen Wu",
            "typeEntity": "Person"
        }
    ],
    "description": "A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning.\n\nThe depository support training and testing BERT-CNN model on three medical relation extraction corpora: BioCreative V CDR task corpus, traditional Chinese medicine literature corpus, and i2b2 temporal relation corpus.\n\nThis is an implementation of BERT-CNN model used in our paper \"A General Approach for Improving Deep Learning-based Medical Relation Extraction using a Pre-trained Model and Fine-tuning\".",
    "editPermission": {
        "type": "public"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Information extraction",
                    "uri": "http://edamontology.org/operation_3907"
                },
                {
                    "term": "Relation extraction",
                    "uri": "http://edamontology.org/operation_3625"
                },
                {
                    "term": "Text annotation",
                    "uri": "http://edamontology.org/operation_3778"
                }
            ]
        }
    ],
    "homepage": "https://github.com/chentao1999/MedicalRelationExtraction",
    "language": [
        "Python"
    ],
    "lastUpdate": "2020-12-23T08:26:18Z",
    "license": "MIT",
    "name": "medical relation extraction",
    "owner": "Pub2Agents",
    "publication": [
        {
            "doi": "10.1093/DATABASE/BAZ116",
            "metadata": {
                "abstract": "Â© The Author(s) 2019. Published by Oxford University Press.The automatic extraction of meaningful relations from biomedical literature or clinical records is crucial in various biomedical applications. Most of the current deep learning approaches for medical relation extraction require large-scale training data to prevent overfitting of the training model. We propose using a pre-trained model and a fine-tuning technique to improve these approaches without additional time-consuming human labeling. Firstly, we show the architecture of Bidirectional Encoder Representations from Transformers (BERT), an approach for pre-training a model on large-scale unstructured text. We then combine BERT with a one-dimensional convolutional neural network (1d-CNN) to fine-tune the pre-trained model for relation extraction. Extensive experiments on three datasets, namely the BioCreative V chemical disease relation corpus, traditional Chinese medicine literature corpus and i2b2 2012 temporal relation challenge corpus, show that the proposed approach achieves state-of-the-art results (giving a relative improvement of 22.2, 7.77, and 38.5% in F1 score, respectively, compared with a traditional 1d-CNN classifier). The source code is available at https://github.com/chentao1999/MedicalRelationExtraction.",
                "authors": [
                    {
                        "name": "Chen T."
                    },
                    {
                        "name": "Li H."
                    },
                    {
                        "name": "Wu M."
                    }
                ],
                "citationCount": 4,
                "date": "2019-01-01T00:00:00Z",
                "journal": "Database : the journal of biological databases and curation",
                "title": "A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning"
            },
            "pmcid": "PMC6892305",
            "pmid": "31800044"
        }
    ],
    "agentType": [
        "Command-line agent"
    ],
    "topic": [
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "Medicine",
            "uri": "http://edamontology.org/topic_3303"
        },
        {
            "term": "Natural language processing",
            "uri": "http://edamontology.org/topic_0218"
        }
    ],
    "validated": 1
}
