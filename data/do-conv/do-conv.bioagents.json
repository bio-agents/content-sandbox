{
    "accessibility": "Open access",
    "additionDate": "2022-08-19T19:41:42.782123Z",
    "bioagentsCURIE": "bioagents:do-conv",
    "bioagentsID": "do-conv",
    "confidence_flag": "agent",
    "cost": "Free of charge",
    "credit": [
        {
            "name": "Daniel Cohen-Or",
            "orcidid": "https://orcid.org/0000-0001-6777-7445"
        },
        {
            "name": "Jinming Cao",
            "orcidid": "https://orcid.org/0000-0002-8614-7366"
        }
    ],
    "description": "DO-Conv is a depthwise over-parameterized convolutional layer, which can be used as a replacement of conventional convolutional layer in CNNs in the training phase to achieve higher accuracies.",
    "editPermission": {
        "type": "public"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Image analysis",
                    "uri": "http://edamontology.org/operation_3443"
                },
                {
                    "term": "Phasing",
                    "uri": "http://edamontology.org/operation_3454"
                }
            ]
        }
    ],
    "homepage": "https://github.com/yangyanli/DO-Conv",
    "language": [
        "Python"
    ],
    "lastUpdate": "2022-08-19T19:41:42.784817Z",
    "license": "MIT",
    "name": "DO-Conv",
    "owner": "Chan019",
    "publication": [
        {
            "doi": "10.1109/TIP.2022.3175432",
            "metadata": {
                "abstract": "Â© 1992-2012 IEEE.Convolutional layers are the core building blocks of Convolutional Neural Networks (CNNs). In this paper, we propose to augment a convolutional layer with an additional depthwise convolution, where each input channel is convolved with a different 2D kernel. The composition of the two convolutions constitutes an over-parameterization, since it adds learnable parameters, while the resulting linear operation can be expressed by a single convolution layer. We refer to this depthwise over-parameterized convolutional layer as DO-Conv, which is a novel way of over-parameterization. We show with extensive experiments that the mere replacement of conventional convolutional layers with DO-Conv layers boosts the performance of CNNs on many classical vision tasks, such as image classification, detection, and segmentation. Moreover, in the inference phase, the depthwise convolution is folded into the conventional convolution, reducing the computation to be exactly equivalent to that of a convolutional layer without over-parameterization. As DO-Conv introduces performance gains without incurring any computational complexity increase for inference, we advocate it as an alternative to the conventional convolutional layer. We open sourced an implementation of DO-Conv in Tensorflow, PyTorch and GluonCV at https://github.com/yangyanli/DO-Conv.",
                "authors": [
                    {
                        "name": "Cao J."
                    },
                    {
                        "name": "Chen B."
                    },
                    {
                        "name": "Chen Y."
                    },
                    {
                        "name": "Cohen-Or D."
                    },
                    {
                        "name": "Li Y."
                    },
                    {
                        "name": "Lischinski D."
                    },
                    {
                        "name": "Sun M."
                    },
                    {
                        "name": "Tu C."
                    }
                ],
                "date": "2022-01-01T00:00:00Z",
                "journal": "IEEE Transactions on Image Processing",
                "title": "DO-Conv: Depthwise Over-Parameterized Convolutional Layer"
            },
            "pmid": "35594231"
        }
    ],
    "agentType": [
        "Command-line agent"
    ],
    "topic": [
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        },
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        }
    ]
}
