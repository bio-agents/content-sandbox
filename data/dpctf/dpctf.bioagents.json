{
    "additionDate": "2021-11-03T14:17:59.885944Z",
    "bioagentsCURIE": "bioagents:dpctf",
    "bioagentsID": "dpctf",
    "confidence_flag": "agent",
    "credit": [
        {
            "name": "Yong Deng",
            "orcidid": "https://orcid.org/0000-0003-0987-2182"
        }
    ],
    "description": "Detail Preserving Coarse-to-Fine Matching for Stereo Matching and Optical Flow.",
    "editPermission": {
        "type": "public"
    },
    "homepage": "https://github.com/Deng-Y/DPCTF",
    "lastUpdate": "2021-11-03T14:17:59.888459Z",
    "name": "DPCTF",
    "owner": "Chan019",
    "publication": [
        {
            "doi": "10.1109/TIP.2021.3088635",
            "metadata": {
                "abstract": "Â© 1992-2012 IEEE.The Coarse-To-Fine (CTF) matching scheme has been widely applied to reduce computational complexity and matching ambiguity in stereo matching and optical flow tasks by converting image pairs into multi-scale representations and performing matching from coarse to fine levels. Despite its efficiency, it suffers from several weaknesses, such as tending to blur the edges and miss small structures like thin bars and holes. We find that the pixels of small structures and edges are often assigned with wrong disparity/flow in the upsampling process of the CTF framework, introducing errors to the fine levels and leading to such weaknesses. We observe that these wrong disparity/flow values can be avoided if we select the best-matched value among their neighborhood, which inspires us to propose a novel differentiable Neighbor-Search Upsampling (NSU) module. The NSU module first estimates the matching scores and then selects the best-matched disparity/flow for each pixel from its neighbors. It effectively preserves finer structure details by exploiting the information from the finer level while upsampling the disparity/flow. The proposed module can be a drop-in replacement of the naive upsampling in the CTF matching framework and allows the neural networks to be trained end-to-end. By integrating the proposed NSU module into a baseline CTF matching network, we design our Detail Preserving Coarse-To-Fine (DPCTF) matching network. Comprehensive experiments demonstrate that our DPCTF can boost performances for both stereo matching and optical flow tasks. Notably, our DPCTF achieves new state-of-the-art performances for both tasks - it outperforms the competitive baseline (Bi3D) by 28.8% (from 0.73 to 0.52) on EPE of the FlyingThings3D stereo dataset, and ranks first in KITTI flow 2012 benchmark. The code is available at https://github.com/Deng-Y/DPCTF.",
                "authors": [
                    {
                        "name": "Deng Y."
                    },
                    {
                        "name": "Feng J."
                    },
                    {
                        "name": "Xiao J."
                    },
                    {
                        "name": "Zhou S.Z."
                    }
                ],
                "citationCount": 1,
                "date": "2021-01-01T00:00:00Z",
                "journal": "IEEE Transactions on Image Processing",
                "title": "Detail Preserving Coarse-to-Fine Matching for Stereo Matching and Optical Flow"
            },
            "pmid": "34138709"
        }
    ],
    "agentType": [
        "Workflow"
    ],
    "topic": [
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        },
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        }
    ]
}
