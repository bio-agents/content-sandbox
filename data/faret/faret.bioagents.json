{
    "additionDate": "2021-01-18T09:44:37Z",
    "bioagentsCURIE": "bioagents:faret",
    "bioagentsID": "faret",
    "confidence_flag": "agent",
    "credit": [
        {
            "name": "Fabian A. Soto",
            "typeEntity": "Person"
        }
    ],
    "description": "FaReT (Face Research Agentkit) is a free and open-source agentkit of three-dimensional models and software to study face perception.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Standardisation and normalisation",
                    "uri": "http://edamontology.org/operation_3435"
                },
                {
                    "term": "Validation",
                    "uri": "http://edamontology.org/operation_2428"
                },
                {
                    "term": "Visualisation",
                    "uri": "http://edamontology.org/operation_0337"
                }
            ]
        }
    ],
    "homepage": "https://github.com/fsotoc/FaReT",
    "language": [
        "Python"
    ],
    "lastUpdate": "2021-03-10T19:58:19Z",
    "license": "GPL-3.0",
    "name": "FaReT",
    "owner": "Kigaard",
    "publication": [
        {
            "doi": "10.3758/S13428-020-01421-4",
            "metadata": {
                "abstract": "© 2020, The Psychonomic Society, Inc.A problem in the study of face perception is that results can be confounded by poor stimulus control. Ideally, experiments should precisely manipulate facial features under study and tightly control irrelevant features. Software for 3D face modeling provides such control, but there is a lack of free and open source alternatives specifically created for face perception research. Here, we provide such agents by expanding the open-source software MakeHuman. We present a database of 27 identity models and six expression pose models (sadness, anger, happiness, disgust, fear, and surprise), together with software to manipulate the models in ways that are common in the face perception literature, allowing researchers to: (1) create a sequence of renders from interpolations between two or more 3D models (differing in identity, expression, and/or pose), resulting in a “morphing” sequence; (2) create renders by extrapolation in a direction of face space, obtaining 3D “anti-faces” and caricatures; (3) obtain videos of dynamic faces from rendered images; (4) obtain average face models; (5) standardize a set of models so that they differ only in selected facial shape features, and (6) communicate with experiment software (e.g., PsychoPy) to render faces dynamically online. These agents vastly improve both the speed at which face stimuli can be produced and the level of control that researchers have over face stimuli. We validate the face model database and software agents through a small study on human perceptual judgments of stimuli produced with the agentkit.",
                "authors": [
                    {
                        "name": "Hays J."
                    },
                    {
                        "name": "Soto F.A."
                    },
                    {
                        "name": "Wong C."
                    }
                ],
                "date": "2020-12-01T00:00:00Z",
                "journal": "Behavior Research Methods",
                "title": "FaReT: A free and open-source agentkit of three-dimensional models and software to study face perception"
            },
            "pmid": "32519291"
        }
    ],
    "topic": [
        {
            "term": "Gene expression",
            "uri": "http://edamontology.org/topic_0203"
        },
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        },
        {
            "term": "Literature and language",
            "uri": "http://edamontology.org/topic_3068"
        }
    ]
}
