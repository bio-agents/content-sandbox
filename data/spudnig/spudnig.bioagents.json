{
    "additionDate": "2021-01-18T07:00:01Z",
    "bioagentsCURIE": "bioagents:spudnig",
    "bioagentsID": "spudnig",
    "confidence_flag": "agent",
    "credit": [
        {
            "email": "linda.drijvers@mpi.nl",
            "name": "Linda Drijvers",
            "orcidid": "https://orcid.org/0000-0001-9154-7033",
            "typeEntity": "Person"
        }
    ],
    "description": "A agentkit for the automatic detection of hand movements and gestures in video data.\n\nThis repository contains the source code of the SPeeding Up the Detection of Non-iconic and Iconic Gestures (SPUDNIG) agentkit for Windows only. A working version of the application can be downloaded here. SPUDNIG is created during my MSc thesis project at the Max Planck Institute Nijmegen. SPUDNIG's purpose is to speed up annotation work of hand gestures in Elan. SPUDNIG takes as input a video file and extracts the gestures and their timing.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Visualisation",
                    "uri": "http://edamontology.org/operation_0337"
                }
            ]
        }
    ],
    "homepage": "https://github.com/jorrip/SPUDNIG",
    "language": [
        "Python"
    ],
    "lastUpdate": "2021-02-21T15:03:52Z",
    "name": "SPUDNIG",
    "owner": "zsmag19",
    "publication": [
        {
            "doi": "10.3758/S13428-020-01350-2",
            "metadata": {
                "abstract": "© 2020, The Author(s).In human face-to-face communication, speech is frequently accompanied by visual signals, especially communicative hand gestures. Analyzing these visual signals requires detailed manual annotation of video data, which is often a labor-intensive and time-consuming process. To facilitate this process, we here present SPUDNIG (SPeeding Up the Detection of Non-iconic and Iconic Gestures), a agent to automatize the detection and annotation of hand movements in video data. We provide a detailed description of how SPUDNIG detects hand movement initiation and termination, as well as open-source code and a short tutorial on an easy-to-use graphical user interface (GUI) of our agent. We then provide a proof-of-principle and validation of our method by comparing SPUDNIG’s output to manual annotations of gestures by a human coder. While the agent does not entirely eliminate the need of a human coder (e.g., for false positives detection), our results demonstrate that SPUDNIG can detect both iconic and non-iconic gestures with very high accuracy, and could successfully detect all iconic gestures in our validation dataset. Importantly, SPUDNIG’s output can directly be imported into commonly used annotation agents such as ELAN and ANVIL. We therefore believe that SPUDNIG will be highly relevant for researchers studying multimodal communication due to its annotations significantly accelerating the analysis of large video corpora.",
                "authors": [
                    {
                        "name": "Drijvers L."
                    },
                    {
                        "name": "Holler J."
                    },
                    {
                        "name": "Ripperda J."
                    }
                ],
                "citationCount": 2,
                "date": "2020-08-01T00:00:00Z",
                "journal": "Behavior Research Methods",
                "title": "Speeding up the detection of non-iconic and iconic gestures (SPUDNIG): A agentkit for the automatic detection of hand movements and gestures in video data"
            },
            "pmcid": "PMC7406525",
            "pmid": "31974805"
        }
    ],
    "topic": [
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "Transcription factors and regulatory sites",
            "uri": "http://edamontology.org/topic_0749"
        }
    ]
}
