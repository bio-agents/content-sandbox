{
  "@context": {
    "bioagents": "https://bio.agents/ontology/",
    "bsc": "http://bioschemas.org/",
    "bsct": "http://bioschemas.org/types/",
    "dct": "http://purl.org/dc/terms/",
    "edam": "http://edamontology.org/",
    "owl": "http://www.w3.org/2002/07/owl#",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@graph": [
    {
      "@id": "https://bio.agents/PathFlowAI",
      "@type": "sc:SoftwareApplication",
      "dct:conformsTo": "https://bioschemas.org/profiles/ComputationalAgent/0.6-DRAFT",
      "sc:additionalType": "Command-line agent",
      "sc:applicationSubCategory": [
        {
          "@id": "edam:topic_0634"
        },
        {
          "@id": "edam:topic_0769"
        },
        {
          "@id": "edam:topic_3474"
        }
      ],
      "sc:citation": {
        "@id": "https://doi.org/10.1101/19003897"
      },
      "sc:description": "A High-Throughput Workflow for Preprocessing, Deep Learning and Interpretation in Digital Pathology | A Convenient High-Throughput Workflow for Preprocessing, Deep Learning Analytics and Interpretation in Digital Pathology | MedRxiv Manuscript: https://www.medrxiv.org/content/10.1101/19003897v1 | Fig. 1. PathFlowAI Framework: a) Annotations and whole slide images are preprocessed in parallel using Dask; b) Deep learning prediction model is trained on the model; c) Results are visualized; d) UMAP embeddings provide diagnostics; e) SHAP framework is used to find important regions for the prediction",
      "sc:featureList": {
        "@id": "edam:operation_3891"
      },
      "sc:license": "MIT",
      "sc:name": "PathFlowAI",
      "sc:url": "https://github.com/jlevy44/PathFlowAI"
    },
    {
      "@id": "https://doi.org/10.1101/19003897",
      "@type": "sc:CreativeWork"
    }
  ]
}